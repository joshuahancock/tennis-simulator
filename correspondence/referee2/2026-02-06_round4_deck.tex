\documentclass[aspectratio=169,11pt]{beamer}

\usetheme{metropolis}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{amssymb}

\definecolor{passgreen}{HTML}{2E7D32}
\definecolor{failred}{HTML}{C62828}
\definecolor{warnamber}{HTML}{F57F17}
\definecolor{infoblue}{HTML}{1565C0}

\newcommand{\cmark}{\textcolor{passgreen}{\checkmark}}
\newcommand{\xmark}{\textcolor{failred}{$\times$}}
\newcommand{\wmark}{\textcolor{warnamber}{$\sim$}}

\title{Referee Report --- Round 4}
\subtitle{Tennis Match Simulator}
\date{2026-02-06}
\author{Referee 2}

\begin{document}

% ============================================================
% SLIDE 1: Title
% ============================================================
\begin{frame}
\titlepage
\end{frame}

% ============================================================
% SLIDE 2: Executive Summary
% ============================================================
\begin{frame}{Verdict: Accept with Minor Revisions}

\textbf{Three of four Round 3 concerns addressed:}

\begin{itemize}
  \item \cmark\ \textbf{Model comparison} now uses identical 1,142-match sample
  \item \cmark\ \textbf{K-factor fix} implements standard per-player Elo correctly
  \item \wmark\ \textbf{Unit tests} expanded to 12, but response misrepresents 2 tests
  \item \wmark\ MC accuracy deferral is acceptable given Elo pivot
\end{itemize}

\vspace{0.8em}

\textbf{New issue found:} K-factor fix introduced a regression in history tracking (silent data loss, no impact on predictions).

\vspace{0.8em}

\textbf{Bottom line:} Core results are valid. Remaining issues are code hygiene.

\end{frame}

% ============================================================
% SLIDE 3: Apples-to-Apples Comparison Confirmed
% ============================================================
\begin{frame}{Elo Advantage Holds on Identical Sample (+9.9pp)}

\begin{table}
\centering
\begin{tabular}{lccc}
\toprule
& \textbf{Elo} & \textbf{Monte Carlo} & \textbf{Difference} \\
\midrule
Accuracy         & \textbf{68.6\%}  & 58.7\%  & \textcolor{passgreen}{+9.9 pp} \\
Brier Score      & \textbf{0.2029}  & 0.2338  & \textcolor{passgreen}{$-$0.0310} \\
Log Loss         & \textbf{0.5913}  & 0.6601  & \textcolor{passgreen}{$-$0.0688} \\
\midrule
Sample           & 1,142            & 1,142   & Identical \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.5em}

\begin{itemize}
  \item Round 3 comparison used different samples (1,499 vs 1,142)
  \item Hypothesis: sample composition inflated Elo advantage
  \item \textbf{Result:} Advantage actually \emph{increased} from +9.6pp to +9.9pp
\end{itemize}

\end{frame}

% ============================================================
% SLIDE 4: K-Factor Fix Verified
% ============================================================
\begin{frame}{Per-Player K-Factors Now Correct}

\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Old (Round 3):}
\begin{table}
\footnotesize
\centering
\begin{tabular}{lc}
\toprule
& K\textsubscript{avg} = 40 \\
\midrule
Winner gains  & 20 \\
Loser loses   & 20 \\
Net           & 0 \\
\bottomrule
\end{tabular}
\end{table}
\vspace{0.3em}
\footnotesize K-factors averaged: $(48+32)/2 = 40$\\
Provisional player learning muted by 17\%

\column{0.48\textwidth}
\textbf{New (Round 4):}
\begin{table}
\footnotesize
\centering
\begin{tabular}{lc}
\toprule
& Per-player K \\
\midrule
Winner gains (K=48) & \textbf{24} \\
Loser loses (K=32)  & \textbf{16} \\
Net                  & +8 \\
\bottomrule
\end{tabular}
\end{table}
\vspace{0.3em}
\footnotesize Standard Elo: each player uses own K-factor\\
Net $\neq 0$ when K-factors differ (by design)
\end{columns}

\vspace{0.8em}
\centering
\cmark\ \textbf{Verified:} Unit test confirms 48$\times$0.5 = 24 and 32$\times$0.5 = 16

\end{frame}

% ============================================================
% SLIDE 5: History Tracking Regression
% ============================================================
\begin{frame}{K-Factor Fix Introduced History Tracking Regression}

\footnotesize
\texttt{07\_elo\_ratings.R:249} references a field that no longer exists:

\vspace{0.3em}

\begin{columns}[T]
\column{0.48\textwidth}
\textbf{Old return structure:}
\begin{itemize}
  \item \texttt{rating\_change} \cmark
\end{itemize}
Single value from \texttt{k\_avg * surprise}

\column{0.48\textwidth}
\textbf{New return structure:}
\begin{itemize}
  \item \texttt{winner\_change} (new)
  \item \texttt{loser\_change} (new)
  \item \texttt{rating\_change} \xmark\ removed
\end{itemize}
\texttt{update\$rating\_change} returns \texttt{NULL}
\end{columns}

\vspace{0.5em}

\textbf{Impact:} History tibble silently drops \texttt{rating\_change} column.
R's \texttt{tibble(..., x = NULL)} omits \texttt{x} without error.
Does \textbf{not} affect predictions or accuracy metrics.

\vspace{0.3em}
\textbf{Fix:} Replace with \texttt{winner\_change} and \texttt{loser\_change}

\end{frame}

% ============================================================
% SLIDE 6: Test Suite Discrepancies
% ============================================================
\begin{frame}{Response Claims Two Tests That Do Not Exist}

\begin{table}
\centering
\scriptsize
\begin{tabular}{clll}
\toprule
\textbf{\#} & \textbf{Response Claims} & \textbf{Actual Test} & \\
\midrule
5  & Per-player K-factors        & Per-player K-factors (48 vs 32)        & \cmark \\
\textcolor{failred}{6}  & \textcolor{failred}{Zero-sum, unequal K}  & \textcolor{failred}{Upsets cause larger changes}  & \xmark \\
9  & calculate\_all\_elo()       & calculate\_all\_elo() integration       & \cmark \\
10 & get\_player\_elo() valid    & get\_player\_elo() default for unknown  & \wmark \\
\textcolor{failred}{11} & \textcolor{failred}{Blending works}      & \textcolor{failred}{predict\_match\_elo() probs}  & \xmark \\
12 & predict\_match\_elo()       & Surface-specific tracking               & \wmark \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.3em}

\textbf{Critical:} ``Zero-sum with unequal K-factors'' would \textbf{fail} if implemented.\\
$K_w\!=\!48$, $K_l\!=\!32$: winner gains 24, loser loses 16 --- net +8, not 0.
Per-player Elo is \emph{deliberately} not zero-sum when K-factors differ.

\end{frame}

% ============================================================
% SLIDE 7: Replication Readiness Scorecard
% ============================================================
\begin{frame}{Replication Readiness: 8/10 (Unchanged)}

\begin{tikzpicture}
  \fill[passgreen!60] (0,0) rectangle (10.4,0.5);
  \fill[gray!30] (10.4,0) rectangle (13,0.5);
  \node[white, font=\bfseries] at (5.2,0.25) {8/10};
\end{tikzpicture}

\vspace{1em}

\begin{columns}[T]
\column{0.48\textwidth}
\cmark\ Folder structure \\
\cmark\ Relative paths \\
\cmark\ Variable naming \\
\cmark\ Script naming \\
\cmark\ Master script \\
\cmark\ README in /code \\
\cmark\ Dependencies (renv.lock) \\
\cmark\ Random seeds \\

\column{0.48\textwidth}
\xmark\ Model comparison not in master pipeline \\
\xmark\ In-text statistics still manual \\
\end{columns}

\end{frame}

% ============================================================
% SLIDE 8: Audit Progress Across Rounds
% ============================================================
\begin{frame}{Four Rounds of Improvement}

\begin{table}
\centering
\footnotesize
\begin{tabular}{lcccc}
\toprule
& \textbf{R1} & \textbf{R2} & \textbf{R3} & \textbf{R4} \\
\midrule
Reproducibility (seeds)       & \xmark & \cmark & \cmark & \cmark \\
Dynamic tour averages         & \xmark & \cmark & \cmark & \cmark \\
Master script \& README       & \xmark & \cmark & \cmark & \cmark \\
Bootstrap CIs on ROI          & \xmark & \cmark & \cmark & \cmark \\
renv.lock                     & \xmark & \xmark & \cmark & \cmark \\
Apples-to-apples comparison   & ---    & ---    & \xmark & \cmark \\
Per-player K-factors          & ---    & ---    & \xmark & \cmark \\
Unit test coverage            & ---    & ---    & \wmark & \wmark \\
\midrule
Replication Score             & 4/10   & 7/10   & 8/10   & 8/10 \\
Verdict                       & Major  & Accept$^*$ & Minor & Accept$^*$ \\
\bottomrule
\end{tabular}
\end{table}

\vspace{0.3em}
\centering
\footnotesize $^*$Accept with Minor Revisions

\end{frame}

% ============================================================
% SLIDE 9: Recommendations
% ============================================================
\begin{frame}{Recommendations (No Re-Review Required)}

\begin{enumerate}
  \item \textbf{Fix history tracking} (\texttt{07\_elo\_ratings.R:249})\\
        Replace \texttt{rating\_change = update\$rating\_change} with\\
        \texttt{winner\_change = update\$winner\_change,}\\
        \texttt{loser\_change = update\$loser\_change}

  \vspace{0.5em}

  \item \textbf{Add missing blending test}\\
        Test \texttt{get\_player\_elo()} with controlled surface/overall Elo values\\
        to verify weighted combination at partial surface match counts

  \vspace{0.5em}

  \item \textbf{Fix test verification command}\\
        Document correct invocation:\\
        \texttt{Rscript -e "source('...'); test\_elo()"}
\end{enumerate}

\end{frame}

\end{document}
